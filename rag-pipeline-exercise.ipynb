{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad32605",
   "metadata": {},
   "source": [
    "# RAG Pipeline Exercise\n",
    "\n",
    "In this exercise you will build and **compare two simple Retrieval-Augmented Generation (RAG) pipelines**.\n",
    "\n",
    "You will work with a small collection of PDF documents (e.g. medical guidelines) and:\n",
    "\n",
    "1. Load and chunk the PDF documents.\n",
    "2. Create a vector index using **embedding model A** (local `BAAI/bge-m3`).\n",
    "3. Create a second index using **embedding model B** (e.g. OpenAI or Gemini embeddings).\n",
    "4. Implement a simple **retriever** and an **answering function** that calls an LLM with retrieved context.\n",
    "5. Automatically **generate questions** from the documents and use them to **compare two RAG configurations**.\n",
    "\n",
    "Cells marked with `# TODO` are **for students to implement**.\n",
    "Everything else is provided scaffolding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf82e6",
   "metadata": {},
   "source": [
    "## 0. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be93ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: langchain-text-splitters in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.11.0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain-text-splitters) (1.1.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from faiss-cpu) (2.3.5)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2 langchain-text-splitters faiss-cpu sentence-transformers openai python-dotenv\n",
    "\n",
    "# TODO (easy): skim the imports and make sure you understand what each library is used for.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import glob\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# LLM / API clients (we will mainly use OpenAI here; Gemini can be added as a bonus)\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68f16980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env (you need to create this file once and add your keys)\n",
    "load_dotenv()\n",
    "\n",
    "deepinfra_key = os.getenv(\"DEEPINFRA_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2719d",
   "metadata": {},
   "source": [
    "## 1. Load PDF documents\n",
    "\n",
    "We assume there is a `data/` folder containing one or more PDF files.\n",
    "\n",
    "**Task:** implement `load_pdfs(glob_path)` so that it:\n",
    "- Iterates over all PDF files matching `glob_path`\n",
    "- Reads them with `PdfReader`\n",
    "- Concatenates the text of all pages into **one long string**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8abcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdfs(glob_path: str = \"data/*.pdf\") -> str:\n",
    "    \"\"\"Load all PDFs matching the pattern and return their combined text.\n",
    "\n",
    "    TODO:\n",
    "    - Use `glob.glob(glob_path)` to iterate over file paths\n",
    "    - For each file, open it in binary mode and create a `PdfReader`\n",
    "    - Loop over `reader.pages` and extract text with the extract_text() function\n",
    "    - Concatenate everything into a single string `text`\n",
    "    - Be robust: skip pages where `extract_text()` returns None\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    for pdf_path in glob.glob(glob_path):\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text is not None:\n",
    "                    text += page_text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "416c3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 230592\n",
      "Preview: Asthma: diagnosis, \n",
      "moni toring and chr onic \n",
      "asthma manag emen t (BTS, \n",
      "NICE, SI GN) \n",
      "NICE guideline \n",
      "Published: 27 No vember 202 4 \n",
      "www .nice.or g.uk/guidance/ng2 45 \n",
      "© NICE 202 4. All right s reserved. Subject t o Notice of right s (https://www .nice.or g.uk/t erms-and-\n",
      "conditions#notice-of -right s).Your r esponsi bility \n",
      "The r ecommendations in t his guideline r epresent t he view of NICE, arriv ed at aft er car eful \n",
      "consideration of t he evidence a vailable. When e xercising t heir judgem\n"
     ]
    }
   ],
   "source": [
    "# Run once and inspect\n",
    "raw_text = load_pdfs(\"data/*.pdf\")\n",
    "print(\"Number of characters:\", len(raw_text))\n",
    "print(\"Preview:\", raw_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0c5a14",
   "metadata": {},
   "source": [
    "## 2. Chunk the text\n",
    "\n",
    "We will split the long text into overlapping chunks.\n",
    "\n",
    "Later you can **experiment** with different `chunk_size` and `chunk_overlap` to see how it affects retrieval.\n",
    "\n",
    "**Task:** start with the given parameters, run once, then try at least one alternative configuration and note the effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4e3f802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG A: 129 chunks produced, first chunk length = 1994\n",
      "RAG B: 260 chunks produced, first chunk length = 978\n"
     ]
    }
   ],
   "source": [
    "# Base configuration (RAG A)\n",
    "chunk_size_a = 2000\n",
    "chunk_overlap_a = 200\n",
    "\n",
    "splitter_a = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size_a,\n",
    "    chunk_overlap=chunk_overlap_a\n",
    ")\n",
    "\n",
    "chunks_a = splitter_a.split_text(raw_text)\n",
    "print(f\"RAG A: {len(chunks_a)} chunks produced, first chunk length = {len(chunks_a[0])}\")\n",
    "\n",
    "# TODO (mini-experiment): change chunk_size / chunk_overlap for RAG B and compare\n",
    "chunk_size_b = 1000    # smaller chunks\n",
    "chunk_overlap_b = 100\n",
    "\n",
    "splitter_b = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size_b,\n",
    "    chunk_overlap=chunk_overlap_b\n",
    ")\n",
    "\n",
    "chunks_b = splitter_b.split_text(raw_text)\n",
    "print(f\"RAG B: {len(chunks_b)} chunks produced, first chunk length = {len(chunks_b[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3511f4",
   "metadata": {},
   "source": [
    "## 3. Create embeddings and a FAISS index\n",
    "\n",
    "We start with **Embedding model A: `BAAI/bge-small-en`** using `sentence-transformers`. You can find a list of more models here: https://huggingface.co/spaces/mteb/leaderboard \n",
    "make sure that the models are not bigger than the one used here. Otherwise the embeddings process will take too long.\n",
    "\n",
    "Then, as an optional extension, you can build **Embedding model B** using OpenAI or Gemini and compare.\n",
    "\n",
    "To keep the exercise manageable, the base version only **requires** BGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b519161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensionality (A): 384\n",
      "FAISS index (A) size: 129\n"
     ]
    }
   ],
   "source": [
    "# Embedding model A (local)\n",
    "model_name_a = \"BAAI/bge-small-en\"\n",
    "embedder_a = SentenceTransformer(model_name_a)\n",
    "\n",
    "# Compute embeddings for all chunks of configuration A\n",
    "embeddings_a = embedder_a.encode(chunks_a, convert_to_numpy=True)\n",
    "\n",
    "dimensions_a = embeddings_a.shape[1]\n",
    "print(\"Embedding dimensionality (A):\", dimensions_a)\n",
    "\n",
    "index_a = faiss.IndexFlatL2(dimensions_a)\n",
    "index_a.add(embeddings_a)\n",
    "print(\"FAISS index (A) size:\", index_a.ntotal)\n",
    "\n",
    "# Persist index/chunks if you like (optional)\n",
    "os.makedirs(\"faiss\", exist_ok=True)\n",
    "faiss.write_index(index_a, \"faiss/faiss_index_a.index\")\n",
    "with open(\"faiss/chunks_a.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks_a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77271916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index (B) size: 260\n"
     ]
    }
   ],
   "source": [
    "# Embedding model B using OpenAI embeddings.\n",
    "\n",
    "# TODO :\n",
    "# - Use `openai_client.embeddings.create(...)` to compute embeddings for `chunks_b`\n",
    "# - Create a second FAISS index `index_b`\n",
    "# - Make sure to check the dimensionality from the first embedding vector\n",
    "\n",
    "\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "response = openai_client.embeddings.create(\n",
    "     model=\"text-embedding-3-small\",\n",
    "    input=chunks_b\n",
    ")\n",
    "embeddings_b = np.array([item.embedding for item in response.data])\n",
    "dim_b = embeddings_b.shape[1]\n",
    "index_b = faiss.IndexFlatL2(dim_b)\n",
    "index_b.add(embeddings_b)\n",
    "print(\"FAISS index (B) size:\", index_b.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339224e",
   "metadata": {},
   "source": [
    "## 4. Implement a simple retriever\n",
    "\n",
    "We now implement a generic retrieval function that:\n",
    "1. Embeds the query.\n",
    "2. Searches the FAISS index.\n",
    "3. Returns the corresponding text chunks.\n",
    "\n",
    "We implement it for configuration A. If you built configuration B, you can reuse the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa6fbf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved chunks: 3\n",
      "Preview of first chunk: and signs of ot her causes of r espirat ory sympt oms but be awar e that e ven if \n",
      "examination r esult s are normal, t he person ma y still ha ve ast hma. [NICE 2017] \n",
      "Initial tr eatmen t and obje cti\n"
     ]
    }
   ],
   "source": [
    "def retrieve_texts(query: str, k: int, index, chunks, embedder) -> list:\n",
    "    \"\"\"Return the top-k most similar chunks for a query.\n",
    "    - Encode the query with `embedder.encode(...)`\n",
    "    - Call `index.search(query_embedding, k)`\n",
    "    - Use the returned indices to select the chunks\n",
    "    - Return a list of strings (chunks)\n",
    "    \"\"\"\n",
    "    query_emb = embedder.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    retrieved = [chunks[i] for i in indices[0]]\n",
    "    return retrieved\n",
    "\n",
    "# Quick sanity check\n",
    "test_query = \"What is the most important factor in diagnosing asthma?\"\n",
    "retrieved_test = retrieve_texts(test_query, k=3, index=index_a, chunks=chunks_a, embedder=embedder_a)\n",
    "print(\"Number of retrieved chunks:\", len(retrieved_test))\n",
    "print(\"Preview of first chunk:\", retrieved_test[0][:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646fdc6",
   "metadata": {},
   "source": [
    "## 5. Implement `answer_query` using an LLM\n",
    "\n",
    "Now we build the actual RAG call:\n",
    "\n",
    "1. Use `retrieve_texts` to get top-`k` chunks.\n",
    "2. Concatenate them into a context string.\n",
    "3. Build a prompt that:\n",
    "   - shows the context\n",
    "   - asks the model to answer the user question based **only** on this context.\n",
    "4. Call the OpenAI chat completion API.\n",
    "\n",
    "This is the **core RAG function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d94610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG answer: I cannot answer this question based on the provided documents.\n"
     ]
    }
   ],
   "source": [
    "def answer_query(query: str, k: int, index, chunks, embedder, client: OpenAI) -> str:\n",
    "    \"\"\"RAG-style answer: retrieve context and ask an LLM.\n",
    "\n",
    "    TODO (students):\n",
    "    - Use `retrieve_texts` to get `k` relevant chunks.\n",
    "    - Join them into a single context string.\n",
    "    - Build a chat prompt that instructs the model to answer *only* using the context.\n",
    "    - Call `client.chat.completions.create(...)` with model `\"gpt-4o-mini\"` (or similar).\n",
    "    - Return the model's answer text.\n",
    "    \"\"\"\n",
    "    retrieved_chunks = retrieve_texts(query, k, index, chunks, embedder)\n",
    "    context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Remember: strings can be concatenated (like an addition)\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant that answers questions based ONLY on the provided context. \"\n",
    "        \"If the answer cannot be found in the context, say 'I cannot answer this question based on the provided documents.' \"\n",
    "        \"Here is the context:\\n\\n\" + context\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "# Quick manual test\n",
    "answer = answer_query(test_query, k=3, index=index_a, chunks=chunks_a, embedder=embedder_a, client=openai_client)\n",
    "print(\"RAG answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86a92e",
   "metadata": {},
   "source": [
    "## 6. Generate questions from random chunks (automatic evaluation set)\n",
    "\n",
    "To compare two RAG configurations, we need **questions**.\n",
    "\n",
    "We will:\n",
    "- randomly sample a few chunks from the corpus,\n",
    "- ask an LLM to generate a **good question** whose answer is contained in the chunk.\n",
    "\n",
    "Then we can use these question–chunk pairs as a small evaluation set.\n",
    "\n",
    "We provide most of the implementation. Your job is mainly to:\n",
    "- inspect the code,\n",
    "- understand the prompt,\n",
    "- maybe tweak the number of chunks or retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb899fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What diagnostic tests and approaches are evaluated for their accuracy in diagnosing asthma, and how might the implementation of digital inhaler monitors influence adherence and asthma control among patients?\n",
      "  From chunk preview: people suspect ed of ast hma \n",
      "• evidence r eview  C: diagnostic t est accuracy of peak e xpirat ory flow variability f o...\n",
      "\n",
      "Q2: How might the incorporation of FeNO measurement into primary care practices influence the management and treatment outcomes for patients with asthma, particularly regarding treatment adjustments and adherence?\n",
      "  From chunk preview: (which will be an annual r eview f or most people). \n",
      "The F eNO le vel is a pr oxy measur e of air way inflammation. It c...\n",
      "\n",
      "Q3: What changes did the committee make to the recommendations for antihypertensive treatment in adults with type 2 diabetes, particularly regarding the use of beta-blockers and the initial treatment options for individuals of Black African or African-Caribbean descent?\n",
      "  From chunk preview: block ers in cer tain gr oups of y ounger people. The committ ee discussed t his \n",
      "recommendation and agr eed t hat beta-...\n",
      "\n",
      "Q4: What are the key considerations and proposed changes discussed by the committee in updating the 2011 hypertension management guidelines, particularly concerning same-day referrals and the treatment of severe hypertension?\n",
      "  From chunk preview: review ed the 2011 r ecommendations and agr eed t hat t hey should be updat ed by \n",
      "consensus based on t heir clinical e ...\n",
      "\n",
      "Q5: What lifestyle changes and treatment recommendations does the committee propose for managing hypertension, and how might the lack of routine use of relaxation therapies impact current practices in the healthcare system?\n",
      "  From chunk preview: hyper tension should be on encouraging people t o mak e lifestyle changes, such as taking \n",
      "regular e xercise and maintai...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_questions_for_random_chunks(chunks, num_chunks: int = 5, max_retries: int = 2):\n",
    "    selected_chunks = random.sample(chunks, num_chunks)\n",
    "    qa_pairs = []\n",
    "\n",
    "    for chunk in selected_chunks:\n",
    "        prompt = prompt = (\n",
    "            \"Based on the following text, generate an insightful question that covers its key content:\\n\\n\"\n",
    "            \"Text:\\n\" + chunk + \"\\n\\n\"\n",
    "            \"Question:\"\n",
    "        )\n",
    "\n",
    "        question = None\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                completion = openai_client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                question = completion.choices[0].message.content.strip()\n",
    "                if question:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(\"Error while generating question, retrying...\", e)\n",
    "\n",
    "        if question is None:\n",
    "            question = \"Error: could not generate question.\"\n",
    "\n",
    "        qa_pairs.append((chunk, question))\n",
    "\n",
    "    return qa_pairs\n",
    "\n",
    "questions = generate_questions_for_random_chunks(chunks_a, num_chunks=5, max_retries=2)\n",
    "for i, (chunk, q) in enumerate(questions, 1):\n",
    "    print(f\"Q{i}: {q}\\n  From chunk preview: {chunk[:120]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0eaf5",
   "metadata": {},
   "source": [
    "## 7. Compare two RAG configurations\n",
    "\n",
    "Now we can:\n",
    "- Use the generated questions,\n",
    "- Answer them with RAG configuration A (BGE + chunking A),\n",
    "- (Optional) Answer them with RAG configuration B (e.g. different chunking and/or different embeddings),\n",
    "- Compare the answers qualitatively.\n",
    "\n",
    "To keep the exercise manageable, we start with config A only.\n",
    "If you implemented config B, reuse `answer_query` with `index_b`, `chunks_b`, and your second embedder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a292474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What diagnostic tests and approaches are evaluated for their accuracy in diagnosing asthma, and how might the implementation of digital inhaler monitors influence adherence and asthma control among patients?\n",
      "Answer A: The diagnostic tests and approaches evaluated for their accuracy in diagnosing asthma include:\n",
      "\n",
      "1. Spirometry \n",
      "2. Bronchodilator reversibility testing \n",
      "3. Peak expiratory flow variability \n",
      "4. Skin prick test in children \n",
      "5. IgE levels in children \n",
      "6. Fractional exhaled nitric oxide (FeNO) measures \n",
      "7. Eosinophil blood count measures \n",
      "8. Bronchial challenge with histamine and methacholine \n",
      "9. Bronchial challenge test with mannitol \n",
      "10. Exercise bronchial challenge testing \n",
      "11. Combination of tests\n",
      "\n",
      "Regarding digital inhaler monitors, while they showed improvement in adherence to treatment, this did not lead to significant improvement in measures of asthma control. Furthermore, there was an unexplained increase in hospital admissions among users compared to usual care. Digital inhalers are more expensive than conventional devices and are not recommended for routine use in the NHS, although they may be beneficial for selected patients, particularly those considering biologic therapy. Further research is needed to identify which individuals and circumstances would most benefit from their use.\n",
      "Source chunk preview: people suspect ed of ast hma \n",
      "• evidence r eview  C: diagnostic t est accuracy of peak e xpirat ory flow variability f or \n",
      "the diagnosis of ast hma \n",
      "• ...\n",
      "------------------------------------------------------------\n",
      "Question: How might the incorporation of FeNO measurement into primary care practices influence the management and treatment outcomes for patients with asthma, particularly regarding treatment adjustments and adherence?\n",
      "Answer A: I cannot answer this question based on the provided documents.\n",
      "Source chunk preview: (which will be an annual r eview f or most people). \n",
      "The F eNO le vel is a pr oxy measur e of air way inflammation. It can t herefore be v ery useful  ...\n",
      "------------------------------------------------------------\n",
      "Question: What changes did the committee make to the recommendations for antihypertensive treatment in adults with type 2 diabetes, particularly regarding the use of beta-blockers and the initial treatment options for individuals of Black African or African-Caribbean descent?\n",
      "Answer A: The committee decided not to retain the recommendation for considering beta-blockers in certain groups of younger people, as they are rarely used as step 1 antihypertensive treatment and there is no established relationship between beta-blocker use in primary hypertension and a reduction in cardiovascular events.\n",
      "\n",
      "For adults with type 2 diabetes of any age, the committee agreed to retain the recommendation to start treatment with an angiotensin-converting enzyme (ACE) inhibitor, but it was broadened to include the option of an angiotensin II receptor blocker (ARB) as they are now considered cost equivalent and clinically equivalent.\n",
      "\n",
      "Additionally, for individuals of Black African or African-Caribbean descent with type 2 diabetes, the previous recommendation for step 1 dual therapy with an ACE inhibitor and either a diuretic or a calcium channel blocker was not retained. The committee concluded that there was insufficient evidence to recommend starting dual therapy in any subgroup of people with type 2 diabetes, although they noted that some individuals may need to start step 2 drug therapy in the short term if their target blood pressure is not achieved with ACE inhibitor or ARB monotherapy.\n",
      "Source chunk preview: block ers in cer tain gr oups of y ounger people. The committ ee discussed t his \n",
      "recommendation and agr eed t hat beta-block ers ar e rar ely used as ...\n",
      "------------------------------------------------------------\n",
      "Question: What are the key considerations and proposed changes discussed by the committee in updating the 2011 hypertension management guidelines, particularly concerning same-day referrals and the treatment of severe hypertension?\n",
      "Answer A: The committee reviewed the 2011 recommendations and agreed that they should be updated based on their clinical expertise. Key considerations and proposed changes included:\n",
      "\n",
      "1. **Same-Day Referral Criteria**: The committee aimed to clarify which features warranted same-day referral and which would require further investigation. They noted that it can be difficult to differentiate between accelerated hypertension and severe hypertension.\n",
      "\n",
      "2. **Broader Referral Criteria**: They discussed the advantages and disadvantages of having broader criteria for same-day referral. While broader criteria would increase referrals to hospitals, it would also reduce the risk of missing individuals who need urgent treatment.\n",
      "\n",
      "3. **Emergency Symptoms**: They agreed to add some emergency symptoms to the existing recommendation to assist healthcare professionals in deciding when to refer patients.\n",
      "\n",
      "4. **Investigations Before Treatment**: The committee highlighted that some individuals with severe hypertension could be receiving unnecessary treatment based solely on the diagnosis of severe hypertension. They recommended conducting investigations for target organ damage quickly before offering treatment in cases of severely raised blood pressure without other concerning symptoms.\n",
      "\n",
      "5. **Follow-Up for Severe Hypertension**: They agreed that checking blood pressure again within 7 days for those with no target organ damage would ensure that individuals with severe hypertension are followed up and offered appropriate treatment.\n",
      "\n",
      "6. **Need for Further Research**: The committee acknowledged the need for further research, especially concerning individuals with extreme hypertension (220/120 mmHg or higher) or emergency symptoms, and developed a recommendation for research on same-day hospital specialist assessments to inform future recommendations. \n",
      "\n",
      "These proposed changes aimed to enhance the clarity and effectiveness of hypertension management in clinical practice.\n",
      "Source chunk preview: review ed the 2011 r ecommendations and agr eed t hat t hey should be updat ed by \n",
      "consensus based on t heir clinical e xper tise. In par ticular t he ...\n",
      "------------------------------------------------------------\n",
      "Question: What lifestyle changes and treatment recommendations does the committee propose for managing hypertension, and how might the lack of routine use of relaxation therapies impact current practices in the healthcare system?\n",
      "Answer A: The committee proposes encouraging people to mak e lifestyle changes, such as taking regular exercise and maintaining a healthy weight, for managing hypertension. Additionally, while relaxation therapies were not recommended for routine use in the 2011 guideline and are not currently used in practice for the management of primary hypertension in adults, the committee noted that people may try them as part of their treatment to reduce blood pressure, though the uptake has been low.\n",
      "\n",
      "The lack of routine use of relaxation therapies means that current practice will not be affected by the removal of the 2011 recommendation, as the therapies were not integrated into standard treatment approaches for hypertension. Thus, the emphasis remains on other established methods, such as antihypertensive drug treatment and lifestyle modifications.\n",
      "Source chunk preview: hyper tension should be on encouraging people t o mak e lifestyle changes, such as taking \n",
      "regular e xercise and maintaining a healt hy weight. \n",
      "The c ...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def answer_generated_questions(question_tuples, k, index, chunks, embedder, client):\n",
    "    results = []\n",
    "    for chunk, question in question_tuples:\n",
    "        answer = answer_query(question, k, index, chunks, embedder, client)\n",
    "        results.append({\n",
    "            \"chunk\": chunk,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer\n",
    "        })\n",
    "    return results\n",
    "\n",
    "results_a = answer_generated_questions(\n",
    "    questions,\n",
    "    k=5,\n",
    "    index=index_a,\n",
    "    chunks=chunks_a,\n",
    "    embedder=embedder_a,\n",
    "    client=openai_client,\n",
    ")\n",
    "\n",
    "for item in results_a:\n",
    "    print(\"Question:\", item[\"question\"])\n",
    "    print(\"Answer A:\", item[\"answer\"])\n",
    "    print(\"Source chunk preview:\", item[\"chunk\"][:150], \"...\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec212b7",
   "metadata": {},
   "source": [
    "Add RAG B and create a comparison table\n",
    "\n",
    "If you implemented a second configuration (e.g. different chunking + OpenAI embeddings):\n",
    "\n",
    "1. Build `index_b` and `embedder_b`.\n",
    "2. Run `results_b = answer_generated_questions(..., index_b, chunks_b, embedder_b, client)`.\n",
    "3. For each question, compare:\n",
    "   - Which answer is more complete / specific?\n",
    "   - Which one is better grounded in the source chunk?\n",
    "4. Summarise your findings in a short **markdown cell** or a small table.\n",
    "\n",
    "---\n",
    "\n",
    "This concludes the core RAG exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda81a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
